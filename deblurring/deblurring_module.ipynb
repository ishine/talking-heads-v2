{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deblurring_module.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsRedMgt7Mb5",
        "outputId": "5b810c56-5cb8-443b-bcdf-c77b7acf2ae7"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-0cd23c16-d7c0-07b4-0275-9235c4199c6d)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ2sUBzpctb0"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ3ywj5Msip1"
      },
      "source": [
        "# Deblurring Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItPhgVkVlx31"
      },
      "source": [
        "\n",
        "class DeblurringModule(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    super(DeblurringModule, self).__init__()\n",
        "\n",
        "    relu = nn.ReLU(inplace=True)\n",
        "    conv_in = nn.Conv2d(3,64,3,1,1,bias=False)\n",
        "    conv_out = nn.Conv2d(64,3,3,1,1,bias=False)\n",
        "    conv_mid = nn.Conv2d(64,64,3,1,1,bias=False)\n",
        "\n",
        "    layers = []\n",
        "    layers.append(conv_in)\n",
        "    layers.append(relu)\n",
        "    for i in range(10):\n",
        "      layers.append(conv_mid)\n",
        "      layers.append(relu)\n",
        "    layers.append(conv_out)\n",
        "    \n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, img):\n",
        "    out = self.model(img)\n",
        "    final_out = torch.add(out,img)\n",
        "    return final_out\n",
        "\n",
        "def init_model(model, state_file=None):\n",
        "  if state_file is None:\n",
        "    for param in model.parameters():\n",
        "        if param.dim()>1:\n",
        "            torch.nn.init.xavier_uniform_(param)\n",
        "  else:\n",
        "    ckpt = torch.load(state_file)\n",
        "    model.load_state_dict(ckpt)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_HRJvOpodye"
      },
      "source": [
        "\n",
        "class DeblurringDataset(Dataset):\n",
        "  def __init__(self, data_dir='/content/drive/MyDrive/Colab Datasets/MEAD_video/M003',batchsize=32):\n",
        "    self.files = glob.glob(data_dir+'/**/*.mp4',recursive=True)\n",
        "    self.batchsize = batchsize\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    f = self.files[idx]\n",
        "    vid = cv2.VideoCapture(f)\n",
        "    num_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    start_frame = random.randint(0,num_frames-self.batchsize-1)\n",
        "    vid.set(1,start_frame)\n",
        "    frames_blur = np.empty((self.batchsize,256,256,3))\n",
        "    frames_tgt = np.empty((self.batchsize,256,256,3))\n",
        "    for i in range(self.batchsize):\n",
        "      ret, frame = vid.read()\n",
        "      frame_tgt = self.crop_and_downsample(frame)\n",
        "      im = Image.fromarray(frame_tgt)\n",
        "      im = im.filter(ImageFilter.BoxBlur(1.5))\n",
        "      frame_blur = np.array(im)\n",
        "      frames_blur[i] = frame_blur\n",
        "      frames_tgt[i] = frame_tgt\n",
        "\n",
        "    frames_blur = (np.swapaxes(frames_blur,1,3)/255.).astype('float32')\n",
        "    frames_tgt = (np.swapaxes(frames_tgt,1,3)/255.).astype('float32')\n",
        "\n",
        "    return torch.tensor(frames_blur).cuda(), torch.tensor(frames_tgt).cuda()\n",
        "\n",
        "  def crop_and_downsample(self, img, img_dim=256):\n",
        "    h, w, c = img.shape\n",
        "    crop_width = (w - h) // 2\n",
        "    img_crop = img[0:h,crop_width:w-crop_width]\n",
        "    img_resize = cv2.resize(img_crop,dsize=(img_dim,img_dim))\n",
        "\n",
        "    return img_resize"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR3R3AdD_dHw"
      },
      "source": [
        "def write_training_images(img_dir, epoch, base_img, tgt_img, full_stack, output):\n",
        "    images = []\n",
        "    for baseimg, tgtimg, fullstack, tgtemotion, out in zip(base_img, tgt_img, full_stack, tgt_emotion, output):\n",
        "        baseimg = baseimg.numpy()\n",
        "        tgtimg = np.swapaxes(tgtimg.detach().cpu().numpy(),0,2) * 255\n",
        "        lmks = np.swapaxes(fullstack.detach().cpu().numpy()[8:11],0,2) * 255\n",
        "        out = np.swapaxes(out.detach().cpu().numpy(),0,2) * 255\n",
        "        concat = np.concatenate((baseimg,tgtimg,lmks,out),axis=1)\n",
        "        cv2.putText(concat, tgtemotion, (256*2,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1, cv2.LINE_AA)\n",
        "        images.append(concat)\n",
        "    \n",
        "    img_grid = np.concatenate(images,axis=0)\n",
        "    filename = f'{img_dir}epoch_{epoch:0>3d}.jpg'\n",
        "    cv2.imwrite(filename,img_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u93Bc4H87JBl"
      },
      "source": [
        "# initialise writer and paths\n",
        "experiment_name = 'exp_1_run_1'\n",
        "writer = SummaryWriter(f'/content/drive/MyDrive/runs/{experiment_name}')\n",
        "PATH_model_base = f'/content/drive/MyDrive/models/{experiment_name}/'\n",
        "PATH_image_base = f'/content/drive/MyDrive/images/{experiment_name}/'\n",
        "os.mkdir(PATH_model_base)\n",
        "os.mkdir(PATH_image_base)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fUwAfVRzgaA"
      },
      "source": [
        "# initialise model, data, optimizer and loss\n",
        "model = DeblurringModule()\n",
        "init_model(model)\n",
        "model.to('cuda')\n",
        "dataset = DeblurringDataset('/content/drive/MyDrive/MEAD_video/M003', batchsize=16)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.5, 0.999))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8EVOxd6ta_N",
        "outputId": "d924d616-a62a-41a1-9233-83565e1e322f"
      },
      "source": [
        "# run dimensions\n",
        "start_epoch = 0\n",
        "training_epochs = 100\n",
        "model_save_freq = 10\n",
        "img_save_freq = 5\n",
        "train_split=0.8\n",
        "random.seed(0)\n",
        "indices = list(range(len(dataset)))\n",
        "train_indices = random.sample(indices,int(len(indices)*train_split))\n",
        "test_indices = [idx for idx in indices if idx not in train_indices]\n",
        "\n",
        "#epoch loop\n",
        "for epoch in range(start_epoch, start_epoch + training_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_start = time.time()\n",
        "    training_loss = 0.\n",
        "    test_loss = 0.\n",
        "\n",
        "    random.shuffle(train_indices)\n",
        "    \n",
        "    #training\n",
        "    for idx in train_indices:\n",
        "\n",
        "        #get targets and predictions\n",
        "        blurry, target = dataset[idx]\n",
        "        predictions = model(blurry)\n",
        "\n",
        "        # calculate losses\n",
        "        loss = criterion(predictions, blurry)\n",
        "\n",
        "        #training step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #update loss\n",
        "        training_loss += loss.item()\n",
        "\n",
        "    #testing\n",
        "    for idx in test_indices:\n",
        "      with torch.no_grad():\n",
        "\n",
        "        model.eval()\n",
        "        blurry_test, target_test = dataset[idx]\n",
        "        predictions_test = model(blurry_test)\n",
        "        loss = criterion(predictions_test, blurry_test)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    #log epoch metrics\n",
        "    writer.add_scalar('training loss', training_loss / len(dataset), epoch)\n",
        "    writer.add_scalar('test loss', test_loss / len(dataset), epoch)\n",
        "\n",
        "    #checkpoint model\n",
        "    if epoch % model_save_freq == 0:\n",
        "        PATH_model = PATH_model_base + f'epoch_{epoch}.pth'\n",
        "        torch.save(model.state_dict(),PATH_model)\n",
        "\n",
        "    #save image examples\n",
        "    #if epoch % img_save_freq == 0:\n",
        "    #    write_training_images(PATH_image_base, epoch, base_img, tgt_img, full_stack, tgt_emotion, output)\n",
        "\n",
        "    #print metrics\n",
        "    print(f\"\"\"end of epoch {epoch}: \n",
        "    training loss = {training_loss / len(dataset)}\n",
        "    test loss = {test_loss / len(dataset)} \n",
        "    epoch time taken = {int(time.time()-epoch_start)} s\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of epoch 0: \n",
            "    training loss = 1.7999643450204008e-09\n",
            "    test loss = 1.1541443158164122e-10 \n",
            "    epoch time taken = 189 s\n",
            "end of epoch 1: \n",
            "    training loss = 3.388697979072773e-10\n",
            "    test loss = 6.487672759567511e-11 \n",
            "    epoch time taken = 195 s\n",
            "end of epoch 2: \n",
            "    training loss = 2.1241406798370805e-10\n",
            "    test loss = 4.490683784223809e-11 \n",
            "    epoch time taken = 198 s\n",
            "end of epoch 3: \n",
            "    training loss = 1.5381860995765702e-10\n",
            "    test loss = 3.406206441401097e-11 \n",
            "    epoch time taken = 194 s\n",
            "end of epoch 4: \n",
            "    training loss = 1.2121819328089454e-10\n",
            "    test loss = 2.7976612938389083e-11 \n",
            "    epoch time taken = 194 s\n",
            "end of epoch 5: \n",
            "    training loss = 1.0107799425653237e-10\n",
            "    test loss = 2.3717383562459644e-11 \n",
            "    epoch time taken = 195 s\n",
            "end of epoch 6: \n",
            "    training loss = 8.649032850915448e-11\n",
            "    test loss = 2.0545216353719963e-11 \n",
            "    epoch time taken = 196 s\n",
            "end of epoch 7: \n",
            "    training loss = 7.597631083503813e-11\n",
            "    test loss = 1.823407765139452e-11 \n",
            "    epoch time taken = 192 s\n",
            "end of epoch 8: \n",
            "    training loss = 6.77512414756118e-11\n",
            "    test loss = 1.6358033011588003e-11 \n",
            "    epoch time taken = 192 s\n",
            "end of epoch 9: \n",
            "    training loss = 6.118418729047044e-11\n",
            "    test loss = 1.4714237302934785e-11 \n",
            "    epoch time taken = 194 s\n",
            "end of epoch 10: \n",
            "    training loss = 5.575582635590788e-11\n",
            "    test loss = 1.351960111521471e-11 \n",
            "    epoch time taken = 193 s\n",
            "end of epoch 11: \n",
            "    training loss = 5.111969544957785e-11\n",
            "    test loss = 1.2436707523371535e-11 \n",
            "    epoch time taken = 193 s\n",
            "end of epoch 12: \n",
            "    training loss = 4.7230553540567756e-11\n",
            "    test loss = 1.158120201423323e-11 \n",
            "    epoch time taken = 196 s\n",
            "end of epoch 13: \n",
            "    training loss = 4.376254509934815e-11\n",
            "    test loss = 1.0751125433357417e-11 \n",
            "    epoch time taken = 192 s\n",
            "end of epoch 14: \n",
            "    training loss = 4.082495018080373e-11\n",
            "    test loss = 9.994505780772692e-12 \n",
            "    epoch time taken = 193 s\n",
            "end of epoch 15: \n",
            "    training loss = 3.819632570408323e-11\n",
            "    test loss = 9.329915215015688e-12 \n",
            "    epoch time taken = 192 s\n",
            "end of epoch 16: \n",
            "    training loss = 3.567226560716364e-11\n",
            "    test loss = 8.798612733643565e-12 \n",
            "    epoch time taken = 192 s\n",
            "end of epoch 17: \n",
            "    training loss = 3.354316268352462e-11\n",
            "    test loss = 8.259397697791005e-12 \n",
            "    epoch time taken = 192 s\n",
            "end of epoch 18: \n",
            "    training loss = 3.1446458695606385e-11\n",
            "    test loss = 7.788646052852096e-12 \n",
            "    epoch time taken = 192 s\n",
            "end of epoch 19: \n",
            "    training loss = 2.9936020906149787e-11\n",
            "    test loss = 7.380399323257575e-12 \n",
            "    epoch time taken = 192 s\n"
          ]
        }
      ]
    }
  ]
}