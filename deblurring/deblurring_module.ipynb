{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deblurring_module.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsRedMgt7Mb5",
        "outputId": "a4a3a88b-9d41-4fa5-e438-6ee5ece912f9"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-365c34a9-7a2d-8d61-7c27-a5f55720056c)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ2sUBzpctb0"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import glob\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ3ywj5Msip1"
      },
      "source": [
        "# Deblurring Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItPhgVkVlx31"
      },
      "source": [
        "class DeblurringModule(nn.Module):\n",
        "  def __init__(self, kernel_size=3):\n",
        "    assert kernel_size%2 == 1, 'kernel size must be odd' \n",
        "    super(DeblurringModule, self).__init__()\n",
        "\n",
        "    padding = kernel_size//2\n",
        "    relu = nn.ReLU(inplace=True)\n",
        "    conv_in = nn.Conv2d(3, 64, kernel_size, stride=1, padding=padding,bias=False)\n",
        "    conv_out = nn.Conv2d(64, 3, kernel_size, stride=1, padding=padding, bias=False)\n",
        "    conv_mid = nn.Conv2d(64, 64, kernel_size, stride=1, padding=padding, bias=False)\n",
        "\n",
        "    layers = []\n",
        "    layers.append(conv_in)\n",
        "    layers.append(relu)\n",
        "    for i in range(10):\n",
        "      layers.append(conv_mid)\n",
        "      layers.append(relu)\n",
        "    layers.append(conv_out)\n",
        "    \n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, img):\n",
        "    out = self.model(img)\n",
        "    final_out = torch.add(out,img)\n",
        "    return final_out\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_HRJvOpodye"
      },
      "source": [
        "class DeblurringDataset(Dataset):\n",
        "  def __init__(self, data_dir='/content/drive/MyDrive/Colab Datasets/MEAD_video/M003',batchsize=32):\n",
        "    self.files = glob.glob(data_dir+'/**/*.mp4',recursive=True)\n",
        "    self.batchsize = batchsize\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    f = self.files[idx]\n",
        "    vid = cv2.VideoCapture(f)\n",
        "    num_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    start_frame = random.randint(0,num_frames-self.batchsize-1)\n",
        "    vid.set(1,start_frame)\n",
        "    frames_blur = np.empty((self.batchsize,256,256,3))\n",
        "    frames_tgt = np.empty((self.batchsize,256,256,3))\n",
        "    for i in range(self.batchsize):\n",
        "      ret, frame = vid.read()\n",
        "      frame_tgt = self.crop_and_downsample(frame)\n",
        "      im = Image.fromarray(frame_tgt)\n",
        "      im = im.filter(ImageFilter.BoxBlur(1.5))\n",
        "      frame_blur = np.array(im)\n",
        "      frames_blur[i] = frame_blur\n",
        "      frames_tgt[i] = frame_tgt\n",
        "\n",
        "    frames_blur = (np.swapaxes(frames_blur,1,3)/255.).astype('float32')\n",
        "    frames_tgt = (np.swapaxes(frames_tgt,1,3)/255.).astype('float32')\n",
        "\n",
        "    return torch.tensor(frames_blur).cuda(), torch.tensor(frames_tgt).cuda()\n",
        "\n",
        "  def crop_and_downsample(self, img, img_dim=256):\n",
        "    h, w, c = img.shape\n",
        "    crop_width = (w - h) // 2\n",
        "    img_crop = img[0:h,crop_width:w-crop_width]\n",
        "    img_resize = cv2.resize(img_crop,dsize=(img_dim,img_dim))\n",
        "\n",
        "    return img_resize"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-_IszDPjEUf"
      },
      "source": [
        "def cat_images(blurry,target,predictions):\n",
        "  i = random.randint(0,len(blurry)-1)\n",
        "  grid = torch.cat([blurry[i],predictions[i],target[i]],axis=1)\n",
        "  grid = grid.detach().cpu().numpy()\n",
        "  grid = np.swapaxes(grid,0,2)\n",
        "  grid = grid * 255\n",
        "  return grid\n",
        "\n",
        "  \n",
        "def init_model(model, state_file=None):\n",
        "  if state_file is None:\n",
        "    for param in model.parameters():\n",
        "        if param.dim()>1:\n",
        "            torch.nn.init.xavier_uniform_(param)\n",
        "  else:\n",
        "    ckpt = torch.load(state_file)\n",
        "    model.load_state_dict(ckpt)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u93Bc4H87JBl"
      },
      "source": [
        "# initialise writer and paths\n",
        "experiment_name = 'L1_corrected'\n",
        "writer = SummaryWriter(f'/content/drive/MyDrive/Colab Notebooks/talkingheads/runs/deblurring/{experiment_name}')\n",
        "PATH_model_base = f'/content/drive/MyDrive/Colab Notebooks/talkingheads/models/deblurring/{experiment_name}/'\n",
        "PATH_image_base = f'/content/drive/MyDrive/Colab Notebooks/talkingheads/Deblurring Images/{experiment_name}/'\n",
        "os.mkdir(PATH_model_base)\n",
        "os.mkdir(PATH_image_base)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fUwAfVRzgaA"
      },
      "source": [
        "# initialise model, data, optimizer and loss\n",
        "model = DeblurringModule()\n",
        "init_model(model)\n",
        "model.to('cuda')\n",
        "dataset = DeblurringDataset(batchsize=16)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.5, 0.999))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8EVOxd6ta_N",
        "outputId": "0570ec97-05a6-4982-935e-a8c4ad46f0ce"
      },
      "source": [
        "# run dimensions\n",
        "start_epoch = 1\n",
        "training_epochs = 50\n",
        "model_save_freq = 1\n",
        "img_save_freq = 1\n",
        "eval_freq = 5\n",
        "train_split=0.8\n",
        "random.seed(0)\n",
        "indices = list(range(len(dataset)))\n",
        "train_indices = random.sample(indices,int(len(indices)*train_split))\n",
        "test_indices = [idx for idx in indices if idx not in train_indices]\n",
        "\n",
        "#epoch loop\n",
        "for epoch in range(start_epoch, start_epoch + training_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_start = time.time()\n",
        "    training_loss = 0.\n",
        "    test_loss = 0.\n",
        "\n",
        "    random.shuffle(train_indices)\n",
        "    \n",
        "    #training\n",
        "    for idx in train_indices:\n",
        "\n",
        "        #get targets and predictions\n",
        "        blurry, target = dataset[idx]\n",
        "        predictions = model(blurry)\n",
        "\n",
        "        # calculate losses\n",
        "        loss = criterion(predictions, target)\n",
        "\n",
        "        #training step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #update loss\n",
        "        training_loss += loss.item()\n",
        "\n",
        "    #testing\n",
        "    if epoch % eval_freq == 0:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for idx in test_indices:\n",
        "                blurry_test, target_test = dataset[idx]\n",
        "                predictions_test = model(blurry_test)\n",
        "                loss = criterion(predictions_test, target_test)\n",
        "                test_loss += loss.item()\n",
        "        writer.add_scalar('test loss', test_loss / len(test_indices), epoch)\n",
        "\n",
        "    #log epoch metrics\n",
        "    writer.add_scalar('training loss', training_loss / len(train_indices), epoch)\n",
        "    \n",
        "\n",
        "    #checkpoint model\n",
        "    if epoch % model_save_freq == 0:\n",
        "        PATH_model = PATH_model_base + f'epoch_{epoch}.pth'\n",
        "        torch.save(model.state_dict(),PATH_model)\n",
        "\n",
        "    #save image examples\n",
        "    if epoch % img_save_freq == 0:\n",
        "        img_grid = cat_images(blurry,target,predictions)\n",
        "        filename = f'{PATH_image_base}epoch_{epoch:0>3d}.jpg'\n",
        "        cv2.imwrite(filename,img_grid)\n",
        "\n",
        "    #print metrics\n",
        "    print(f\"\"\"end of epoch {epoch}: \n",
        "    training loss = {training_loss / len(train_indices)}\n",
        "    test loss = {(test_loss / len(test_indices)) if epoch%eval_freq==0 else \"N/A\"} \n",
        "    epoch time taken = {int(time.time()-epoch_start)} s\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end of epoch 1: \n",
            "    training loss = 0.010642534519672094\n",
            "    test loss = N/A \n",
            "    epoch time taken = 316 s\n"
          ]
        }
      ]
    }
  ]
}